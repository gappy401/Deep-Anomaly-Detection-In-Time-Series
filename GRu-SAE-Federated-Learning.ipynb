{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU Model Overview\n",
    "The Gated Recurrent Unit (GRU) is a type of Recurrent Neural Network (RNN) designed to handle sequences of data. It is similar to the Long Short-Term Memory (LSTM) network but with a simplified architecture. GRUs are particularly useful for tasks involving temporal or sequential data due to their ability to capture dependencies over time.\n",
    "\n",
    "Components of the GRU Model:\n",
    "GRU Layers:\n",
    "\n",
    "Update Gate: Determines how much of the past information needs to be passed along to the future. It decides what new information should be updated.\n",
    "Reset Gate: Controls how much of the past information should be forgotten.\n",
    "Candidate Activation: Generates a new candidate for the hidden state, based on the reset gate and the previous hidden state.\n",
    "Hidden State Calculation: Combines the old hidden state and the new candidate activation, weighted by the update gate, to produce the final hidden state.\n",
    "Encoder:\n",
    "\n",
    "Input Layer: Accepts the input sequence data.\n",
    "GRU Layers: Processes the input sequence through one or more GRU layers. Each GRU layer updates its hidden state based on the input and previous hidden state, capturing temporal dependencies.\n",
    "Decoder:\n",
    "\n",
    "Dense Layers: After processing the sequence data with GRUs, the output is passed through dense layers to produce predictions or further process the encoded features.\n",
    "Output Layer: Generates the final output based on the processed sequence data.\n",
    "How It Works:\n",
    "Sequence Processing: GRUs process input data sequentially, maintaining and updating hidden states that capture information from previous time steps. This makes them suitable for tasks like time series forecasting, language modeling, and sequential pattern recognition.\n",
    "\n",
    "Gates Mechanism:\n",
    "\n",
    "Update Gate: Determines how much of the previous hidden state to retain and how much to update with new information.\n",
    "Reset Gate: Determines how much of the past information to forget, allowing the model to adapt to new data.\n",
    "Candidate Activation: Provides a new potential value for the hidden state, considering both the previous state and the new input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import tensorflow as tf \n",
    "def load_and_preprocess_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data = data.dropna()  \n",
    "    return data\n",
    "\n",
    "def prepare_features_and_labels(data):\n",
    "    features = ['TP2', 'DV_pressure', 'Oil_temperature', 'Motor_current', 'DV_eletric', 'Towers', 'LPS', 'Oil_level', 'Caudal_impulses']\n",
    "    target = 'class'\n",
    "    X = data[features].values\n",
    "    y = data[target].values\n",
    "    return X, y\n",
    "\n",
    "def balance_and_sample(X, y, sample_fraction=0.4):\n",
    "    \"\"\"Sample and balance classes.\"\"\"\n",
    "    X, y = shuffle(X, y, random_state=42)\n",
    "    sample_size = int(sample_fraction * len(X))\n",
    "    X_sample, y_sample = X[:sample_size], y[:sample_size]\n",
    "    \n",
    "    classes = np.unique(y_sample)\n",
    "    max_samples = max([np.sum(y_sample == cls) for cls in classes])\n",
    "    \n",
    "    X_balanced = []\n",
    "    y_balanced = []\n",
    "    \n",
    "    for cls in classes:\n",
    "        X_cls = X_sample[y_sample == cls]\n",
    "        y_cls = y_sample[y_sample == cls]\n",
    "        \n",
    "        X_balanced.append(X_cls[:max_samples])\n",
    "        y_balanced.append(y_cls[:max_samples])\n",
    "    \n",
    "    X_balanced = np.vstack(X_balanced)\n",
    "    y_balanced = np.hstack(y_balanced)\n",
    "    \n",
    "    return X_balanced, y_balanced\n",
    "\n",
    "def preprocess_data(data):\n",
    "    if 'timestamp' not in data.columns or 'class' not in data.columns:\n",
    "        raise ValueError(\"Data must contain 'timestamp' and 'class' columns.\")\n",
    "    \n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'], errors='coerce')\n",
    "    data = data.dropna(subset=['timestamp'])\n",
    "    data['month'] = data['timestamp'].dt.to_period('M')\n",
    "    months = data['month'].astype(str).unique()\n",
    "    \n",
    "    if len(months) < 4:\n",
    "        raise ValueError(\"Not enough distinct months to split into global and client data.\")\n",
    "    \n",
    "    months.sort()\n",
    "    first_two_months = months[:2]\n",
    "    last_two_months = months[-2:]\n",
    "    \n",
    "    global_data = data[data['month'].astype(str).isin(first_two_months)]\n",
    "    client1_data = data[data['month'].astype(str) == last_two_months[0]]\n",
    "    client2_data = data[data['month'].astype(str) == last_two_months[1]]\n",
    "    \n",
    "    if global_data.empty or client1_data.empty or client2_data.empty:\n",
    "        raise ValueError(\"One or more of the filtered datasets are empty.\")\n",
    "    \n",
    "    return global_data, client1_data, client2_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_gradients(gradients, compression_factor=0.1):\n",
    "    \"\"\"Quantize gradients to reduce communication overhead.\"\"\"\n",
    "    compressed_gradients = {}\n",
    "    for name, grad in gradients.items():\n",
    "        # Quantize gradients (e.g., to 8-bit precision)\n",
    "        compressed_gradients[name] = (grad / np.max(np.abs(grad)) * 127).astype(np.int8)\n",
    "    return compressed_gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gru_model(input_shape):\n",
    "    \"\"\"Create a GRU model.\"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = GRU(64, return_sequences=True)(inputs)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = GRU(32)(x)\n",
    "    x = Dense(50, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_communication_time(func, *args, **kwargs):\n",
    "    \"\"\"Measure the time taken for a function to execute.\"\"\"\n",
    "    start_time = time.time()\n",
    "    result = func(*args, **kwargs)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    return result, elapsed_time\n",
    "\n",
    "def compress_gradients(gradients):\n",
    "    \"\"\"Apply gradient compression (e.g., quantization or sparsification).\"\"\"\n",
    "    compressed_gradients = []\n",
    "    for grad in gradients:\n",
    "        # Example of simple quantization: round gradients to the nearest integer\n",
    "        compressed_gradients.append(tf.round(grad))\n",
    "    return compressed_gradients\n",
    "\n",
    "def federated_learning(global_data, client1_data, client2_data):\n",
    "    \"\"\"Perform federated learning with GRU model, tracking communication time.\"\"\"\n",
    "    \n",
    "    # Prepare global data\n",
    "    print(\"Preparing global data...\")\n",
    "    X_global, y_global = prepare_features_and_labels(global_data)\n",
    "    X_global, y_global = balance_and_sample(X_global, y_global, sample_fraction=0.4)\n",
    "    \n",
    "    # Prepare client data\n",
    "    print(\"Preparing client data...\")\n",
    "    X_client1, y_client1 = prepare_features_and_labels(client1_data)\n",
    "    X_client2, y_client2 = prepare_features_and_labels(client2_data)\n",
    "    X_client1, y_client1 = balance_and_sample(X_client1, y_client1, sample_fraction=0.4)\n",
    "    X_client2, y_client2 = balance_and_sample(X_client2, y_client2, sample_fraction=0.4)\n",
    "    \n",
    "    # Reshape data for GRU (e.g., [samples, timesteps, features])\n",
    "    X_global = X_global[:, np.newaxis, :]\n",
    "    X_client1 = X_client1[:, np.newaxis, :]\n",
    "    X_client2 = X_client2[:, np.newaxis, :]\n",
    "    \n",
    "    # Create and train global model\n",
    "    print(\"Creating and training global model...\")\n",
    "    model = create_gru_model(input_shape=(X_global.shape[1], X_global.shape[2]))\n",
    "    _, train_time_global = measure_communication_time(model.fit, X_global, y_global, epochs=10, batch_size=32, verbose=2)\n",
    "    print(f\"Time to train global model: {train_time_global:.2f} seconds.\")\n",
    "    \n",
    "    # Fine-tune model on client data\n",
    "    client_data = [\n",
    "        (X_client1, y_client1, \"Client 1\"),\n",
    "        (X_client2, y_client2, \"Client 2\")\n",
    "    ]\n",
    "    \n",
    "    print(\"Fine-tuning model on client data...\")\n",
    "    for X_client, y_client, client_name in tqdm(client_data, desc=\"Clients\", unit=\"client\"):\n",
    "        print(f\"Fine-tuning on {client_name}...\")\n",
    "        \n",
    "        # Measure time to fine-tune\n",
    "        def train_func():\n",
    "            model.fit(X_client, y_client, epochs=5, batch_size=32, verbose=2)\n",
    "        \n",
    "        _, update_time = measure_communication_time(train_func)\n",
    "        print(f\"Time to fine-tune on {client_name}: {update_time:.2f} seconds.\")\n",
    "        \n",
    "        # Compress gradients and simulate communication\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Calculate logits\n",
    "            logits = model(X_client, training=True)\n",
    "            \n",
    "            # Ensure y_client has the correct shape\n",
    "            y_client = tf.reshape(y_client, (-1, 1))\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = tf.keras.losses.binary_crossentropy(y_client, logits)\n",
    "        \n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        compressed_gradients = compress_gradients(gradients)\n",
    "        print(f\"Compressed gradients size for {client_name}: {sum(tf.size(grad).numpy() for grad in compressed_gradients) / (1024 * 1024):.2f} MB\")\n",
    "    \n",
    "    # Evaluate the updated global model\n",
    "    print(\"Evaluating the updated global model...\")\n",
    "    y_global_pred = (model.predict(X_global) > 0.5).astype(int)\n",
    "    print(\"Model Classification Report:\")\n",
    "    print(classification_report(y_global, y_global_pred))\n",
    "    print(\"Model Accuracy Score:\", accuracy_score(y_global, y_global_pred))\n",
    "    \n",
    "    print(\"Federated learning completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing global data...\n",
      "Preparing client data...\n",
      "Creating and training global model...\n",
      "Epoch 1/10\n",
      "5145/5145 - 19s - 4ms/step - accuracy: 0.9733 - loss: 0.0538\n",
      "Epoch 2/10\n",
      "5145/5145 - 13s - 2ms/step - accuracy: 0.9840 - loss: 0.0355\n",
      "Epoch 3/10\n",
      "5145/5145 - 12s - 2ms/step - accuracy: 0.9897 - loss: 0.0267\n",
      "Epoch 4/10\n",
      "5145/5145 - 12s - 2ms/step - accuracy: 0.9913 - loss: 0.0238\n",
      "Epoch 5/10\n",
      "5145/5145 - 12s - 2ms/step - accuracy: 0.9927 - loss: 0.0207\n",
      "Epoch 6/10\n",
      "5145/5145 - 12s - 2ms/step - accuracy: 0.9936 - loss: 0.0195\n",
      "Epoch 7/10\n",
      "5145/5145 - 13s - 2ms/step - accuracy: 0.9938 - loss: 0.0187\n",
      "Epoch 8/10\n",
      "5145/5145 - 12s - 2ms/step - accuracy: 0.9942 - loss: 0.0180\n",
      "Epoch 9/10\n",
      "5145/5145 - 12s - 2ms/step - accuracy: 0.9947 - loss: 0.0172\n",
      "Epoch 10/10\n",
      "5145/5145 - 12s - 2ms/step - accuracy: 0.9946 - loss: 0.0172\n",
      "Time to train global model: 127.89 seconds.\n",
      "Fine-tuning model on client data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clients:   0%|          | 0/2 [00:00<?, ?client/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning on Client 1...\n",
      "Epoch 1/5\n",
      "2707/2707 - 7s - 2ms/step - accuracy: 0.9971 - loss: 0.0106\n",
      "Epoch 2/5\n",
      "2707/2707 - 6s - 2ms/step - accuracy: 0.9980 - loss: 0.0062\n",
      "Epoch 3/5\n",
      "2707/2707 - 6s - 2ms/step - accuracy: 0.9984 - loss: 0.0059\n",
      "Epoch 4/5\n",
      "2707/2707 - 7s - 2ms/step - accuracy: 0.9986 - loss: 0.0052\n",
      "Epoch 5/5\n",
      "2707/2707 - 7s - 2ms/step - accuracy: 0.9987 - loss: 0.0046\n",
      "Time to fine-tune on Client 1: 32.57 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clients:  50%|█████     | 1/2 [00:34<00:34, 34.13s/client]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed gradients size for Client 1: 0.02 MB\n",
      "Fine-tuning on Client 2...\n",
      "Epoch 1/5\n",
      "2783/2783 - 7s - 2ms/step - accuracy: 0.9965 - loss: 0.0112\n",
      "Epoch 2/5\n",
      "2783/2783 - 7s - 3ms/step - accuracy: 0.9980 - loss: 0.0069\n",
      "Epoch 3/5\n",
      "2783/2783 - 8s - 3ms/step - accuracy: 0.9983 - loss: 0.0060\n",
      "Epoch 4/5\n",
      "2783/2783 - 7s - 3ms/step - accuracy: 0.9984 - loss: 0.0058\n",
      "Epoch 5/5\n",
      "2783/2783 - 8s - 3ms/step - accuracy: 0.9986 - loss: 0.0056\n",
      "Time to fine-tune on Client 2: 36.96 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clients: 100%|██████████| 2/2 [01:11<00:00, 35.92s/client]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed gradients size for Client 2: 0.02 MB\n",
      "Evaluating the updated global model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5145/5145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step\n",
      "Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99    160227\n",
      "           1       0.00      0.00      0.00      4386\n",
      "\n",
      "    accuracy                           0.97    164613\n",
      "   macro avg       0.49      0.50      0.49    164613\n",
      "weighted avg       0.95      0.97      0.96    164613\n",
      "\n",
      "Model Accuracy Score: 0.9733435390886503\n",
      "Federated learning completed.\n"
     ]
    }
   ],
   "source": [
    "file_path = 'Metro-Both-Classes.csv'\n",
    "data = load_and_preprocess_data(file_path)\n",
    "global_data, client1_data, client2_data = preprocess_data(data)\n",
    "federated_learning(global_data, client1_data, client2_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "Stacked Autoencoder (SAE) Model Overview\n",
    "A Stacked Autoencoder (SAE) is a type of neural network used for unsupervised learning, typically for dimensionality reduction or feature learning. It consists of multiple autoencoders stacked on top of each other, forming an encoder-decoder architecture.\n",
    "\n",
    "Components of the Stacked Autoencoder Model:\n",
    "Encoder:\n",
    "\n",
    "Input Layer: Accepts the original input data.\n",
    "Hidden Layers:\n",
    "Dense Layer 1: Reduces the dimensionality from the input space to a smaller intermediate space.\n",
    "Dense Layer 2: Further compresses the representation.\n",
    "Dense Layer 3: Reduces the dimensionality to an even smaller space, often referred to as the bottleneck layer, which captures the most critical features of the data.\n",
    "Output of Encoder: The compressed or encoded representation of the input data.\n",
    "Bottleneck Layer:\n",
    "\n",
    "Dense Layer 4: This is the smallest layer in the network and represents the most compact form of the input data. It captures the most important features for reconstruction.\n",
    "Decoder:\n",
    "\n",
    "Hidden Layers:\n",
    "Dense Layer 5: Expands the compressed representation back to a larger intermediate space.\n",
    "Dense Layer 6: Further expands it.\n",
    "Dense Layer 7: Expands it back to the original input space.\n",
    "Output Layer: Reconstructs the input data from the encoded representation.\n",
    "How It Works:\n",
    "Training Objective: The model is trained to reconstruct the input data as accurately as possible. The loss function used is typically binary cross-entropy or mean squared error, which measures the difference between the input and the reconstructed output.\n",
    "\n",
    "Encoder Function: The encoder compresses the input data into a lower-dimensional representation, which captures the key features of the input.\n",
    "\n",
    "Decoder Function: The decoder then takes this compressed representation and attempts to reconstruct the original input data.\n",
    "\n",
    "Dimensionality Reduction: By forcing the data through the bottleneck layer, the model learns a lower-dimensional representation that captures the essential features while discarding less important information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "def create_autoencoder_model(input_shape):\n",
    "    \"\"\"Create a stacked autoencoder model.\"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    x = Dense(128, activation='relu')(inputs)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    \n",
    "    # Bottleneck (encoded representation)\n",
    "    encoded = Dense(16, activation='relu')(x)\n",
    "    \n",
    "    # Decoder\n",
    "    x = Dense(32, activation='relu')(encoded)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = Dense(input_shape[0], activation='sigmoid')(x)\n",
    "    \n",
    "    autoencoder = Model(inputs, outputs)\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    \n",
    "    return autoencoder\n",
    "\n",
    "def compress_gradients(gradients):\n",
    "    \"\"\"Apply gradient compression (e.g., quantization or sparsification).\"\"\"\n",
    "    compressed_gradients = []\n",
    "    for grad in gradients:\n",
    "        # Example of simple quantization: round gradients to the nearest integer\n",
    "        compressed_gradients.append(tf.round(grad))\n",
    "    return compressed_gradients\n",
    "\n",
    "def measure_communication_time(func, *args, **kwargs):\n",
    "    \"\"\"Measure the time taken for a function to execute.\"\"\"\n",
    "    start_time = time.time()\n",
    "    result = func(*args, **kwargs)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    return result, elapsed_time\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def check_and_handle_nan(arr):\n",
    "    \"\"\"Check for NaN values and handle them by replacing with zeros.\"\"\"\n",
    "    if np.any(np.isnan(arr)):\n",
    "        print(\"Warning: NaN values found. Replacing NaNs with zeros.\")\n",
    "        arr = np.nan_to_num(arr)  # Replace NaNs with zeros\n",
    "    return arr\n",
    "\n",
    "def federated_learning(global_data, client1_data, client2_data):\n",
    "    \"\"\"Perform federated learning with Stacked Autoencoder model, tracking communication time.\"\"\"\n",
    "    \n",
    "    # Prepare global data\n",
    "    print(\"Preparing global data...\")\n",
    "    X_global, y_global = prepare_features_and_labels(global_data)\n",
    "    X_global, y_global = balance_and_sample(X_global, y_global, sample_fraction=0.4)\n",
    "    \n",
    "    # Prepare client data\n",
    "    print(\"Preparing client data...\")\n",
    "    X_client1, y_client1 = prepare_features_and_labels(client1_data)\n",
    "    X_client2, y_client2 = prepare_features_and_labels(client2_data)\n",
    "    X_client1, y_client1 = balance_and_sample(X_client1, y_client1, sample_fraction=0.4)\n",
    "    X_client2, y_client2 = balance_and_sample(X_client2, y_client2, sample_fraction=0.4)\n",
    "    \n",
    "    # Reshape data for Autoencoder (e.g., [samples, features])\n",
    "    X_global = X_global[:, :]\n",
    "    X_client1 = X_client1[:, :]\n",
    "    X_client2 = X_client2[:, :]\n",
    "    \n",
    "    # Create and train global model\n",
    "    print(\"Creating and training global model...\")\n",
    "    model = create_autoencoder_model(input_shape=(X_global.shape[1],))\n",
    "    _, train_time_global = measure_communication_time(model.fit, X_global, X_global, epochs=10, batch_size=32, verbose=2)\n",
    "    print(f\"Time to train global model: {train_time_global:.2f} seconds.\")\n",
    "    \n",
    "    # Fine-tune model on client data\n",
    "    client_data = [\n",
    "        (X_client1, y_client1, \"Client 1\"),\n",
    "        (X_client2, y_client2, \"Client 2\")\n",
    "    ]\n",
    "    \n",
    "    print(\"Fine-tuning model on client data...\")\n",
    "    for X_client, y_client, client_name in tqdm(client_data, desc=\"Clients\", unit=\"client\"):\n",
    "        print(f\"Fine-tuning on {client_name}...\")\n",
    "        \n",
    "        # Measure time to fine-tune\n",
    "        def train_func():\n",
    "            model.fit(X_client, X_client, epochs=5, batch_size=32, verbose=2)\n",
    "        \n",
    "        _, update_time = measure_communication_time(train_func)\n",
    "        print(f\"Time to fine-tune on {client_name}: {update_time:.2f} seconds.\")\n",
    "        \n",
    "        # Compress gradients and simulate communication\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Calculate logits\n",
    "            logits = model(X_client, training=True)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = tf.keras.losses.binary_crossentropy(X_client, logits)\n",
    "        \n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        compressed_gradients = compress_gradients(gradients)\n",
    "        print(f\"Compressed gradients size for {client_name}: {sum(tf.size(grad).numpy() for grad in compressed_gradients) / (1024 * 1024):.2f} MB\")\n",
    "    \n",
    "    # Evaluate the updated global model\n",
    "    print(\"Evaluating the updated global model...\")\n",
    "    X_global_pred = model.predict(X_global)\n",
    "    \n",
    "    # Check and handle NaN values\n",
    "    X_global = check_and_handle_nan(X_global)\n",
    "    X_global_pred = check_and_handle_nan(X_global_pred)\n",
    "    \n",
    "    # Evaluate reconstruction loss\n",
    "    reconstruction_loss = mean_squared_error(X_global, X_global_pred)\n",
    "    print(\"Reconstruction Loss (Mean Squared Error):\", reconstruction_loss)\n",
    "    \n",
    "    print(\"Federated learning completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing global data...\n",
      "Preparing client data...\n",
      "Creating and training global model...\n",
      "Epoch 1/10\n",
      "5145/5145 - 11s - 2ms/step - loss: -2.7707e+20\n",
      "Epoch 2/10\n",
      "5145/5145 - 10s - 2ms/step - loss: nan\n",
      "Epoch 3/10\n",
      "5145/5145 - 9s - 2ms/step - loss: nan\n",
      "Epoch 4/10\n",
      "5145/5145 - 10s - 2ms/step - loss: nan\n",
      "Epoch 5/10\n",
      "5145/5145 - 11s - 2ms/step - loss: nan\n",
      "Epoch 6/10\n",
      "5145/5145 - 8s - 2ms/step - loss: nan\n",
      "Epoch 7/10\n",
      "5145/5145 - 11s - 2ms/step - loss: nan\n",
      "Epoch 8/10\n",
      "5145/5145 - 8s - 1ms/step - loss: nan\n",
      "Epoch 9/10\n",
      "5145/5145 - 8s - 1ms/step - loss: nan\n",
      "Epoch 10/10\n",
      "5145/5145 - 8s - 1ms/step - loss: nan\n",
      "Time to train global model: 93.35 seconds.\n",
      "Fine-tuning model on client data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clients:   0%|          | 0/2 [00:00<?, ?client/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning on Client 1...\n",
      "Epoch 1/5\n",
      "2707/2707 - 4s - 1ms/step - loss: nan\n",
      "Epoch 2/5\n",
      "2707/2707 - 4s - 2ms/step - loss: nan\n",
      "Epoch 3/5\n",
      "2707/2707 - 4s - 1ms/step - loss: nan\n",
      "Epoch 4/5\n",
      "2707/2707 - 4s - 2ms/step - loss: nan\n",
      "Epoch 5/5\n",
      "2707/2707 - 4s - 2ms/step - loss: nan\n",
      "Time to fine-tune on Client 1: 21.00 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clients:  50%|█████     | 1/2 [00:21<00:21, 21.22s/client]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed gradients size for Client 1: 0.02 MB\n",
      "Fine-tuning on Client 2...\n",
      "Epoch 1/5\n",
      "2783/2783 - 5s - 2ms/step - loss: nan\n",
      "Epoch 2/5\n",
      "2783/2783 - 4s - 2ms/step - loss: nan\n",
      "Epoch 3/5\n",
      "2783/2783 - 5s - 2ms/step - loss: nan\n",
      "Epoch 4/5\n",
      "2783/2783 - 4s - 2ms/step - loss: nan\n",
      "Epoch 5/5\n",
      "2783/2783 - 4s - 2ms/step - loss: nan\n",
      "Time to fine-tune on Client 2: 23.14 seconds.\n",
      "Compressed gradients size for Client 2: 0.02 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clients: 100%|██████████| 2/2 [00:44<00:00, 22.29s/client]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the updated global model...\n",
      "\u001b[1m   1/5145\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:20\u001b[0m 121ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5145/5145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step\n",
      "Warning: NaN values found. Replacing NaNs with zeros.\n",
      "Reconstruction Loss (Mean Squared Error): 418.58946532034776\n",
      "Federated learning completed.\n"
     ]
    }
   ],
   "source": [
    "file_path = 'Metro-Both-Classes.csv'\n",
    "data = load_and_preprocess_data(file_path)\n",
    "global_data, client1_data, client2_data = preprocess_data(data)\n",
    "federated_learning(global_data, client1_data, client2_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
